{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b362c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 고차원 벡터로 표현하는 기술\n",
    "# Glove(Global Vectors for Word Representation) 사전 학습된 단어 벡터\n",
    "# 단어간의 의미적 유사도 측정(Semantic Similarity)\n",
    "# 벡터 공간에서 단어관계분석(King - man + woman ~~ Queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103581e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 gensim\n",
    "# 사전학습모델 로드 Glove wiki gigaword -50\n",
    "# 단어벡터 추출 및 기본 정보 확인\n",
    "# 단어 간 유사도 계산\n",
    "# 벡터 연산을 통한 의미관계 분석\n",
    "# 문장 수준의 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5710b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거 : cat = [0,0,0,0,0,1,0,0,0,0] (원핫인코딩)\n",
    "# 단어간의 관계정보가 전혀 없음\n",
    "\n",
    "# 현재 cat [0.2, 0.4, .... 0.6] (50차원 벡터)\n",
    "# 차원 각각이 단어의 의미적 특성을 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38481dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king: [0.9 0.1 0.2 0.8]\n",
      "queen: [0.8 0.2 0.3 0.7]\n",
      "man: [0.5 0.8 0.1 0.3]\n",
      "woman: [0.4 0.9 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 4차원 임베딩 공간\n",
    "word_vectors = {\n",
    "    \"king\": np.array([0.9, 0.1, 0.2, 0.8]),\n",
    "    \"queen\": np.array([0.8, 0.2, 0.3, 0.7]),\n",
    "    \"man\": np.array([0.5, 0.8, 0.1, 0.3]),\n",
    "    \"woman\": np.array([0.4, 0.9, 0.2, 0.2]),\n",
    "}\n",
    "\n",
    "# 각 차원이 의미있는 특성 인코딩\n",
    "for word, vec in word_vectors.items():\n",
    "    print(f\"{word}: {vec}\")\n",
    "# 의미적으로 가까운 단어들의 벡터도 가깝다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721cd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count-based 방법(기존)\n",
    "# cat dog가 함께 나타나는 횟수를 카운트\n",
    "\n",
    "#Prediction-based  word2vec\n",
    "# cat 주변단어로부터 dog를 예측하도록 학습\n",
    "\n",
    "# 이 두가지 방법을 결합한게 Glove   Count통계 + 벡터학습의 최적화 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d705da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "단어 행렬 (Co-occurrence Matrix)\n",
      "============================================================\n",
      "       king    queen   man     woman   is    \n",
      "king        0       2       1       0       2\n",
      "queen       2       0       0       1       2\n",
      "man         1       0       0       2       1\n",
      "woman       0       1       2       0       1\n",
      "is          2       2       1       1       0\n",
      "\n",
      "의미:\n",
      "- king과 queen이 자주 함께 나타남 (2회)\n",
      "- man과 woman도 자주 함께 나타남 (2회)\n",
      "- 모든 단어가 'is'와 함께 나타남\n"
     ]
    }
   ],
   "source": [
    "# 2. GloVe 원리 이해: 공기 행렬과 임베딩 학습\n",
    "import numpy as np\n",
    "\n",
    "# 간단한 코퍼스: \"king is man\" \"queen is woman\"\n",
    "# 공기 행렬 (윈도우 크기 2)\n",
    "cooccurrence_matrix = np.array([\n",
    "    # king queen man woman is\n",
    "    [0,   2,    1,   0,   2],  # king\n",
    "    [2,   0,    0,   1,   2],  # queen\n",
    "    [1,   0,    0,   2,   1],  # man\n",
    "    [0,   1,    2,   0,   1],  # woman\n",
    "    [2,   2,    1,   1,   0],  # is\n",
    "], dtype=float)\n",
    "\n",
    "words = [\"king\", \"queen\", \"man\", \"woman\", \"is\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"단어 행렬 (Co-occurrence Matrix)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"       \" + \"  \".join(f\"{w:6}\" for w in words))\n",
    "for i, word in enumerate(words):\n",
    "    row_str = \"  \".join(f\"{int(cooccurrence_matrix[i][j]):6}\" for j in range(len(words)))\n",
    "    print(f\"{word:6} {row_str}\")\n",
    "\n",
    "print(\"\\n의미:\")\n",
    "print(\"- king과 queen이 자주 함께 나타남 (2회)\")\n",
    "print(\"- man과 woman도 자주 함께 나타남 (2회)\")\n",
    "print(\"- 모든 단어가 'is'와 함께 나타남\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf2b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "# Glove 모델 \n",
    "wv = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72df3b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 'king'의 벡터 표현 (50차원):\n",
      "[ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n",
      "  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n",
      "  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n",
      " -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n",
      " -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n",
      "  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n",
      " -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n",
      " -0.51042 ]\n",
      "벡터 차원 수: 50\n",
      "단어 집합 크기: 400000\n"
     ]
    }
   ],
   "source": [
    "test_word = \"king\"\n",
    "vec = wv[test_word]\n",
    "print(f\"단어 '{test_word}'의 벡터 표현 (50차원):\\n{vec}\")\n",
    "print(f\"벡터 차원 수: {len(vec)}\")\n",
    "print(f\"단어 집합 크기: {len(wv.index_to_key)}\")\n",
    "# 단어 간 유사도 계"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
